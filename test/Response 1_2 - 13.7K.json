{
  "totalTokens": 13709,
  "transcript": "Google підготував достойну відповідь Open. AI. Вам точно сподобається. Open AI збільшує ліміти на останні потужні моделі та втрачає мільйони доларів за те, що ми дякуємо ча GPT. Штучний інтелект навчився розмовляти з дельфінами. Дивимося, що сталося в світі штучного інтелекту та технологій за останній тиждень часу. А сталось багато чого цікавого. Того сідайте зручніше, ставте лайки і будемо починати. Google підготував достойну відповідь Openua і показав світу супердешеву і водночас супер потужну модель Gemini 2.5 Flash. Основна особливість цієї моделі - це те, що ця модель, вона є повністю гібридною. І ось цей от можливість різанного, можливість думання чи мислення можна включати і відключати. Мало того, якщо розробники працюють з цією моделлю, використовують її через API, то можна задавати певний бюджет надумання, що дозволить, знову ж таки, зменшити вартість і більше зробити процес планованим. Ну, і загалом, якщо подивитися на бенчмарки, то окрім того, що модель дійсно має привабливі ціни, вона так само по багатьом тестам, наприклад, як Human Last Exam та по іншим тестам дійсно достойно себе показує порівняно з іншими комерційними конкурентами. Якщо ж говорити про продуктивність моделі і її рівень на Rena Score, тобто наскільки модель дійсно потужно може працювати і ціна - це оця от горизонтальна лінія, то ми бачимо траєкторію, якою рухається Google. Тобто з випуском своїх моделей вони все рухаються правіше до здешевлення. Ну і знову ж таки їхні останні моделі, вони десь постійно залишаються зверху, що означає, що вони є лідерами з точки зору ефективності та продуктивності роботи. Зокрема, це їхні Gemon 2.5 Flash. Бачите, нічим не гірше від 4 О моделі, від GRК 3 моделі, тої самої 4.5 по продуктивності, але так само з точки зору десвизни вона десь в топі знаходиться моделей. Модель Google Flash 2.5 доступна через Google AI Studio. Тобто ми заходимо в інтерфейс, справа в нас є меню вибору. Ми дивимося ось модель, остання версія за 17 квітня. І власне ось тут ми бачимо ці налаштування. То ми можемо включити процес думання або вимкнути його. Ми можемо задати бюджет. Бюджет задається у вигляді токенів. Тобто, якщо я, наприклад, зараз викличу якийсь тестовий промт, проаналізувати це зображення, як доглядати за цією квіткою, то модель починає думати. Ми бачимо ось цей процес сінгу дуже схожий до процесу думання, які зараз є в О3 моделі, в О4 Mini моделі від Open AI. І коли завершується процес домання, ми можемо побачити, знову ж таки нашу фінальну відповідь, а так само скільки токенів модель використала для цього процесу. При умові, що якщо б я тут вказав обмеження, я би бачив, скільки використала в рамках цього мого обмеження. Так само модель Gemini Flash5 доступна з інтерфейсу класичного Gemini. Ось тут в меню ми можемо обрати цей 2,5 Flash Experimental. І ось я дам такий от запит, який прошу проаналізувати останні тарифи Трампа і підкріпити аналіз інформації з інтернету. Тобто модель є мультимодальною, вона вміє працювати з зображенням, зі звуком, вона вміє ходити в інтернет. І ось ми маємо ось таку от відповідь, яка підприклана інформацією з інтернету, а так само базується на основі оцього процесу думання. Так само модель є гібридною з точки зору підключення інструментів. Тобто, якщо потрібно, ця модель вміє в певний момент часу підключати різні інструменти. Чи це робота з файловою системою, чи це з пошуком, чи це з конвой, чи це з іншими інструментами, які доступні в пакеті від Gemini. Як я вже казав, Google дійсно за останній рік часу дуже сильно набирає оберти. І щоб ви зрозуміли наскільки це серйозно, давайте подивимося на цифри. Тобто на 2025 рік компанія Alphabet запланувала 75 млрд доларів на розробку технологій, пов&amp;#39;язані зі штучним інтелектом. Тобто це і хардверні речі, це є софтверні, це є розробки, це їхні Gem та інші речі. В порівнянні з тим самим Open AI, які, ну, насправді власних грошей не мають, вони здебільше ходять і шукають інвесторів. І десь вони кажуть, що ми плануємо підняти е суму в 40 млрд доларів цього року. 25-го року. І лише з них 10 млрд вже компанія СофTбанк та інші компанії оплатили Openю на його розробки. Тобто 10 млрд порівняно з 75 млрдми, які планує Google. Ну, ви самі розумієте діапазон цін. Знову ж таки, Google використовує власні кошти і власні RnD розробки працюють на його благо. Open знову ж таки шукає кошти. Тому я думаю марафон по розробці штучного інтелекту по нових технологіях цього року буде дійсно дуже і дуже цікавим. Ще одна потужна річ, яку зробив Google - це те, що тепер їхню GMA 3 модель можна запустити на локальному, звичайному домашньому комп&amp;#39;ютері або навіть на мобільному телефоні. Вони анонсували новий механізм квантування своєї ж моделі GM3. Якщо подивитися, то з того, що вони описують, використовуючи оце от quantization aware training механізм, вони дуже сильно зменшили використання ресурсів, зокрема пам&amp;#39;яті, яка необхідна для того, щоб запускати GMA3 моделі. Якщо раніше вона запускалася на Nvidia H100, то тепер її можна запустити на домашньому комп&amp;#39;ютері звичайною Nvidia RTX 3090. Ну і ось тут, якщо подивитися порівнянній, скільки взагалі потрібно графічних ресурсів для того, щоб запускати гема порівняно з тим самим Deeps чи Лама. Оці от крапочки це є кількість графічних процесорів, на яких запускається і працює модель. Ну і якщо трошки далі заглипитись в технічні деталі, то оцей от процес квантування, він насправді всім нам досить добре відомий. Єдине, що класична процес ковантування, він відбувається вже після того, як модель була запритрейнена. І відповідно зазвичай якість цього комантування, вона впливає на якість продуктивності моделі. Вона трошки погіршується. Що ж зробив Google? Вони інтегрували оцей от процес квантування в сам процес притренінгу. Тобто вони не чекають, поки модель там притрейнилась і вже її випускають в люди. Вони, коли вона притрейниться, пробують кожен крок якимось чином стискати таким чином, оптимізуючи конфігурацію моделі. Це досить класне таке ноу-хау, яке вони розробили, яке вони придумали. І ось тут насправді на зображенні видно, яким чином оцей от процес квантування впливає на використання пам&amp;#39;яті, на використання ресурсів. Оце їхня 27 млрд параметрів модель. Це от класична модель, а це от квантована. Бачите, в три рази менше необхідно ресурсів для того, щоб працювати з цією моделлю. Де ж можна скачати цю модель, щоб запустити локально на комп&amp;#39;ютері? Прошу дуже. Олаama сервіс всім нам відомий. Можна в ньому прям вибрати конфігурацію моделі, чи звичайну модель класичну, чи ці нові стиснуті квантовані моделі. Скопіювати посилання і прошу дуже можна інсталювати GEMA 3 на власний комп&amp;#39;ютер чи на якийсь мобільний пристрій. У мене на каналі є окреме відео, де я розповідав, як встановити оламу, як через неї можна запускати локальні моделі. Тому, якщо ще не бачили, можете зайти подивитися. Ну і знову Google відзначився. Тільки цього разу їхній CEO компанії Deep Mind Demis HASABIS потрапив на сторінку Times через ряд дуже таких інтригованих і футуристичних прогнозів, які він бачить з точки зору розвитку штучного інтелекту. Ну і ось тут є знову ж таки перелік таких основних речей, які він розповідав в своєму 60тихвилинному інтерв&amp;#39;ю. До речі, можете інтерв&amp;#39;ю подивитися, воно доступно в публічному доступі в інтернеті. Зокрема, Хасабіс говорив, що десь в роки 20, 30, 20-35 все-таки ми досягнемо рівня загального штучного інтелекту. Тобто, ну, здавалось би, там наступних 5-10 років ми зможемо перетнути ось цю межу. Знову ж таки, ще одна така річ, про яку він розповідав і яка буде проривом ближчим часом, це те, що за 5-10 років штучний інтелект почне не просто повторювати ті речі, на основі яких він навчався, а почне дійсно генерувати щось унікальне, щось інноваційне, генерувати якісь гіпотези, генерувати якісь витвори. Тому це теж таку річ він прогнозує. Ну і загалом сфера розвитку медицини, розвитку ліків, вона теж дуже сильно просунеться з появою нового штучного інтелекту. Ну і ось тут, власне, він говорить про те, що протеїн контролює більшість елементів нашого організму, нашого тіла і взагалі оці всі дослідження навколо цього протеїну, структури його до появи ДІПМНДУ. ми там виконали лише 1 млн таких різних навчальних і дослідницьких процедур, то лише з появою дпмайну ми за останній рік часу дозволив нам Яй реалізувати порядка 200 млн різного роду досліджень і проектів. Це дуже великий скачок з точки зору власне медицини і того, як вона рухається далі. Ще одна річ, яку він говорить, це знову ж таки про те лікування, про діагностика, ранню діагностику. І вже дев&amp;#39;ять з 10 компаній на сьогоднішній день використовують штучний інтелект в своїй роботі. Про це ми теж, до речі, сьогодні поговоримо, бо Microsoft теж зробив одну дуже потужну розробку в сфері медицини. Ну і загалом оці всі дослідження, якщо раніше вони займали роки часу, то зараз з використанням штучного інтелекту це є години, можливо дні на дослідження, на якийсь аналіз, на якесь діагностування потрібно витратити. Ну і остання, але не менш важлива річ, знову ж таки, навколо медицини, навколо лікування людей, це те, що за період 10 років до 2035 року AI допоможе вилікувати основні невиліковні хвороби, які ми не можемо сьогодні вилікувати. Він зможе вилікувати до 2035 року. Ну, подивимося, як воно насправді буде. Деміс він людина не остання в індустрії. він 30 років працює дотично до штучного інтелекту, займає досить вагому позицію в компанії Deep Mind, тому я думаю десь його прогнози, до них вартує прислухатися, тому що десь такий тренд він буде. Тому давайте продовжити слідкувати і дивитися, як дійсно оці всі речі будуть впроваджуватись в наше життя. Microsoft теж рухається в сторону AI та медицини і показує копаilotт для лікарів. Ось таку розробку саті надалі нам показав. називається DX GPT. Власне, це та річ, яку будь-який лікар може використовувати, щоб діагностувати різного роду захворювання. Просто ти вводиш в чат текст і тобі модель видає результат. Знову ж таки, ця вся історія була навколо одного інженера, який працює в Microsoft і його дитині було дуже тяжко з одним неврологічним захворюванням. І він вирішив: &amp;quot;Давай, ну, я спробую вирішити цю задачу&amp;quot;. Він написав листа до Саті надалі, каже: &amp;quot;Дивись, в мене така ситуація в сім&amp;#39;ї не дуже хороша&amp;quot;. І Саті виділив круглу суму. Тоді цей інженер разом з командою протягом кількох років почали працювати над ось цім копайлетом для лікарів і розробляти цю модель. Ну і становим на сьогодніш ця модель вже готова. Нею можна користуватися публічно. Вона є доступна. Інтерфейс виглядає ось такий дуже простий. Будь-який лікар Європи, України може нею користуватися. Тут в діалог достатньо ввести симптом англійською мовою і натискнути пошук. І за деякий час модель починає аналізувати свої бази знань, інформацію, якою вона володіє, і видавати схожі симптоми, які відповідають даному опису. З кожним з яких можна детальніше познайомитися, ось прийняти якесь рішення, можна завантажити додаткові симптоми. І таким чином модель працює і дає оці от власне лікарські діагнози. Знову ж таки, вона ніяким чином не заміняє лікарів, вона лише радить. І якщо мене слухає наше Міністерство цивирки технологій, я думаю, це буде дуже класна теж інтеграція для наших лікарів з України, для того, щоб вони теж могли додатково мати таку третю точку зору з точки визначення діагнозу для пацієнтів з їхніми хворобами і допомагали їм. Знову ж таки, ця річ працює лише, якщо захворювання дуже-дуже важкі, дуже складні. Тобто, якщо там у вас насморк чи якась там звичайна дуже просте захворювання, ну, вона насправді не дуже допоможе, але ця модель була навчена власне на дуже складних захворюваннях, які ще маловідомі, мало лікується, і вона намагається, знову ж таки знайти ось ці от поради з точки зору діагностування цих захворювань на ранньому етапі. Сем Альтман вирішив розщедритись і збільшити ліміти на використання нових моделей. Тому станом на сьогодні використання О3 моделі дає нам можливість мати 100 транзакцій протягом тижня часу, а використання О4 міній дає можливість мати 100 транзакцій кожного дня. Ну, а як на мене, це досить хороший крок з точки зору ефективності використання моделей. Ну, і ще одна річ, у вас, коли заходите в chatggt, може з&amp;#39;явитись ось такий от діалог, який говорить про те, що deep resarch тепер є інший. І коли воно говорить інше, мається на увазі про те, що вони теж дають можливість використовувати Deep resarch і його розширюють можливості для всіх користувачів, навіть тих, хто має безкоштовні плани на чаt. Що ж вони роблять? Вони використовують замість класичного цього агента Deep Research певну реалізацію своєї О4 міні-моделі, яка лежить в основі такого легкого depressch. Насправді, з точки зору там точності і якості результатів, ця от легка версія Deepресерчуch, вона нічим не гірша за класичний deep resеarch, але вона точно в десятки разів дешевша. З точки зору економії ресурсів, економії GPU, це правильний крок. Ну і як результат, ця вся річ, вона буде працювати набагато швидше та ефективніше. Ну і знову ж таки, такий маленький теж апдейт, який вони внесли. Бачите, з меню повністю пропала 4о модель, де була можливість планувати задачі. І насправді з&amp;#39;явилось ось таке от повідомлення, що тепер можна використовувати О3 моделі та Оіні для планування якихось задач. Тобто, якщо у вас там є задача там кожного ранку досліджувати якісь новини, якийсь ринок, якісь акції, якісь деталі шукати в інтернеті або робити якісь прості нагадування, прошу дуже. можете просто текстом написати, редагувати діалог з нагадуванням і в результаті працювати з О3 моделю чи О4 міні для такого от ранкового чи там по певній годині аналізу. Ну і ще один фановий момент, про який Сем Альтман написав в себе в твіттері, що не забувайте дякувати чаті. Тобто свого роду він затролив свій попередній пост, який він робив в Твіттері про те, що насправді, коли ми дякуємо або використовуємо якісь фрази, будь ласка, такі от невеличкі речі, то Chat GBT і загалом Openua втрачає мільйони доларів на ось ці от обробки цих повідомлень. Ну і він далі тролить і каже: &amp;quot;Не забувайте дякувати&amp;quot;. Тому я вам кажу, якщо вам зручно, користуйтесь, не забувайте дякувати, тому що воно і так з точки зору оптимізації костів рухається на зниження. Ми бачимо, що робить Open AI. Вони постійно знижують використання ресурсів. Тому прошу дуже тестуйте нові моделі. І зараз є їх ще більше і вони є більш доступніші з точки зрення використання оцих от лімітів. Open AA потрохи починає інтегрувати рекламу в пошук з ча. Насправді це зараз ще не реклама, а лише інтеграція з медійним виданням Washington Post, яке оголосило OpenA партнерство. Ну і в результаті, якщо ми будемо шукати якусь інформацію, вона буде доступна через медійне видання Washington Post, то ча буде її підтягувати і давати як посилання. Але я думаю питання реклами, питання ось такого промо посилань, промо проплачених якихось інформаційних джерел, вона не за горами і ближчим часом воно теж буде інтегруватися в chatт GPT, тому що за цим стоїть бізнес, за цим стоять дуже великі гроші. Ну і, до речі, якщо ви не знали, то chat ChatGPT так само дає можливість, використовуючи їхні API, вибирати на яких сайтах робити пошук. Тобто ми можемо задавати ряд параметрів, чи це сайт, чи це якісь конкретні домени, чи це AI.com, або інші. І в параметрах пошуку ми можемо коригувати, що шукати, як шукати. Я спробував таку річ реалізувати в звичайному chat GPT без API. І ось мені chbt допоміг видати, зігнорувати ось такі от query. Я їх можу копіювати. Ось бачите, тут я вказую знайди мені інформацію про СМА за останні 7 днів часу і шукається на сайті лише x.com. Якщо подивитися, я отут пробував запускати кілька запитів. Ось на x.com в мене є посилання про сема Альтмана. Далі я спробував дати видання New York Times і бачите, New York Times чітко блокує ось такі запити. І тут сам ча каже: &amp;quot;Дивіться, скоріш за все New York Times вони інтегрували на рівні Robots txt блокування. Я не можу взяти звітом інформацію. Forbes так само, бачите, блокує&amp;quot;. Ну а ось X.com і тепер Washington Post та інші видання досить легко видають цю інформацію. Тому ось такий от коротенький, простенький промт. Можете копіювати ним, користуватися. А ви, як бачите, з тою популярністю, яку отримав ча, це десь порядка 800 млн користувачів, можливо вже мільярд користувачів ним користується. Це 1/8 населення планети. Всі тепер зацікавлені свій трафік направляти туда: &amp;quot;А давай покажи мені новини. А давай покажи мій продукт. А давай покажи мені це рішення чи якусь інформацію&amp;quot;. І chat GBT буде це згадувати в своїх посиланнях. Тому, як я казав, не за горами то день, коли воно перетвориться в такий от AI Google, де буде проплачена реклама, проплачені якісь видання. Ну, подивимося, як воно буде розвиватися. Open AI так само хоче вийти на ринок розробки програмного забезпечення і планує купити Winsurf. Ось такою новиною годить інтернет про те, що компанія Open AI за 3 млрд доларів планує купити Winsurf, таку собі AI coding платформу. Вона дуже схожа до lavable, до курсор. До речі, в мене на каналі є окреме відео про курсор, про таку платформу. Якщо ще не бачили, можете подивитися. Так ось, Winsorf - це такого ж плану платформа. І Open AI таким чином намагається якось підсилити свої розробницькі продукти. Це той їхній кодекс CLI або GPT і можливість інтеграції застосунків. До речі, я дуже часто користуюся цією от можливістю десктопного чат GPT, який вміє інтегруватися з розробницькими застосунками. Дуже класна ця річ. Ну і таким чином він хоче стати на рівні з тим самим Майкрософтом, який має на сьогоднішній день під Hubco Pilot курсор, про який я теж розповідав. Clт модель, яка зараз рахується одною топовою моделлю для розробників і більшість людей нею користуються, якщо стоїть питання розробки програмного забезпечення. І взагалі цікавим фактом є те, що свого часу, коли вони анонсували ось цю от модель GPT4.1, один, то CEO компанії Winorf до них прийшов в гості. Ну, як на мене, це вже той був ранній сигнал про те, що Openua щось замисляє. Тому давайте почекаємося, коли ця подія, ця новина стане офіційною. Ну, насправді, я буду дуже радий, якщо станеться ось така от класна інтеграція Open AI пinerf. Хто хоче Мануса або оператора дома в себе на домашньому комп&amp;#39;ютері? Manus - це один з таких агентів, про який я розповідав на одному зі своїх відео, які є на каналі. Так ось, компанія CorteT, вони пропонують такого власного відкритого агента, який називається SUA. Як ви бачите з цього відео, компанія Корк - це всього-навсього кілька інженерів, які от розробили ось цю суну, цю агентивний інтерфейс, який вміє думати, планувати, робити якісь дії, використовує ряд різних інструментів. Це свого роду той самий Deep Search, тільки на стероїдах. І ось тут вони в прикладі так само відео показують, як він може там шукати інформацію, аналізувати. От з вас з&amp;#39;являється зліва чат, справа ось це от діалогове вікно робота агента. Ось бачите, він ходить теж по сайтам, клікає, вміє навігуватися. Таким чином він працює. І якщо зайти до них на вебсайт, то ось так виглядає їхній інтерфейс. Можна залогуватися, почати працювати Sна, але ось така от кнопочка не з&amp;#39;являється найняти на роботу Суна. Тобто ми вже там підходимо до того, що ми можемо наймати агентів на роботу. Що класно в цьому Sunна? Це є open sourceна розробка. Вона є доступна через GitHub. Ось тут детальніше є розписано, як можна її завантажити. Ось тут є архітектура, як вона побудована. Бачите, їхній фронтенд на нексті, Cortex Agent Press. Так само є якась їхня база даних локальна. Ну і ряд інструментарій, які вони використовують. Ну, якщо проскролити нижче, то власне з точки зору там інсталяції все дуже-дуже просто проходить. По великому рахунку вам треба це все скачати, підключити ключі від Open AI або Antropic і вуаля на локальному комп&amp;#39;ютері ви будете мати ось такого от свого власного агента. Я ще не пробував встановити, планую з тим детальніше трошки далі розібратись і обов&amp;#39;язково напишу в нашій ші спільноті. А загалом не забувайте заходити до нашої ще спільноти, тому що я там стараюсь кожного дня якісь описувати цікаві речі, які не завжди викладаю у відео. Тому доєднійтесь, там у нас класна спільнота. Буде точно цікаво і корисно. Штучний інтелект навчився розмовляти з дельфінами. І цього разу компанія Google знову відзначилась. Вони розробили ось таку цікаву річ, яка називається Dolphin Gemma. Це набір різних AI моделей, натренованих суто на розуміння сигналів від дельфінів. І загалом оця от організація Wild Dolphin Project, ще починаючи з 1985 року, роками накопичували, накопичували інформацію, звукові записи, там відеозаписи про те, як дельфіни між собою взаємодіють, як вони спілкуються. Ну і по мірі отримання цих даних із появою штучного інтелекту Google взявся за цю роботу і давай це все оцифровувати, давай це все якось пробувати натренувати модель для того, щоб ми розуміли, як дельфіни взаємодіють. Ну і загалом вони використали порядка 400 млн різних параметрів, які є в моделі, і от якось її там оптимізували для того, щоб вона багнально працювала на мобільному телефоні. Тобто в нас є GEMA локальна модель та їхня мала мовна модель, суперпотужна. Вони її натренували на такій кількості даних і тепер вона дуже легко запускається на Android Pixel телефоні і може ця людина, яка дослідник, от вона може одягати цей пристрій на себе. Ось десь тут в неї цей є мобільний телефон. Вона чіпляє десь там він зашитий. І цей пристрій, він от бачите, потрапляє в воду. Людина в себе має цей датчик, який там слухає, який реагує, і передає якісь сигнали. Тобто бачите, цей датчик передає сигнали, дельфіни якось на нього реагують і він сприймає інформацію. І ось тут детальніше вони показують, як цей девайс виглядає. І ось власне це його інтерпретація цього девайсу з piixel телефоном під капотом дemмо модель натренована для звуку, для голосів, які дельфіни розуміють. І ось так воно виглядає. Тобто з точки зору дешевизни, такої розробки, це прямо у це дуже круте рішення. Взагалі оці всі рішення, які от Google нам показує, вони дійсно досить кост ефектів. Ну навіщо придумувати якісь там незрозумілі нові складні пристрої? Давайте візьмемо то, що вже є зроблено, і попробуємо це інтегрувати з моделями, з пристроями. Ну і таким чином реалізовувати ось такі от складні задачі, як розмова з дельфінами. Вийшов найемоційніший генератор аудіо з тексту. Два студенти зібралися і розробили ось таку от дію. Тільки це не та дія, яка ми маємо в мобільному телефоні. Це нарія. Це open sourceна відкрита модель, яка може перетворювати текст в звук. І насправді якість цього перетворення, вона прирівнюється до більшості комерційних рішень. Доступна версія на hug-gen face. Ось тут є приклади. Давайте ось цей от голос я включу і спробуємо зігнорувати аудіо. І я вам включу, щоб ви послухали, як воно звучить, як воно виглядає. Насправді звучання просто грандіозне. За кілька секунд я отримую відео. Давайте послухаємо. Вау, воу, простоу. Ну, я думаю, тут питання лише часу, коли Opena, Google та інші комерційні компанії, які зараз беруть шалені гроші за перетворення тексту в аудіо, почнуть переосмислювати і або знижати ціни, або ми з вами почнемо користуватися ось такими крутими, відкритими рішення, які можна завантажити і все локально використовувати на комп&amp;#39;ютері. Давайте ще трошки пробіжимось, що сталося в світі мультимедіа і генеративного AI для зображень, відео. І зокрема компанія MJNY дала можливість всім підписникам використовувати редактор зображень. Я насправді останнім часом не користуюсь Journey, але з того, що люди пишуть, дуже класна річ, коли, наприклад, згенерував зображення в GPT 4О, приніс M Journey і можна якісь там корективи внести, підтюнити, можна якісь водяні знаки забрати. Тому для тих, хто любить користуватись M Journey, як на мене, це дуже класна і цікава новина. Ну і в світі генерації відео використання MAI теж компанія Luma вносить корективи. Вона пропонує свою модель Ray2, яка тепер вміє дуже добре працювати з кутами камери. І ось тут на відео вони показують, як ці всі кути камер можна налаштувати через пром через інтерфейс Лума. І взагалі мені здається, що світ генеративного відео, він дуже стрімко розвивається. Є усі от лідери Runwayй, Лума, Клинк, які постійно дуже часто вносять, вносять, вносять якісь оновлення. Тепер, напевно, заходячи в Instagram чи Facebook, чи навіть на YouTube, навряд чи ми зможемо чітко відрізнити, чи це відео, чи ця реклама, вона була згенерована студією, чи це штучний інтелект постарався і ось нам показує ось таку от класну картинку. А на цьому все. Ось такі були новини тижні зі світу. AI. Дякую всім за перегляди. Підтримуйте наш канал та ставайте спонсорами. А ще долучайтесь до нашої ще спільноти, бо я вірю, що за цими технологіями майбутнє. З вами був Ігор. Всім па-па і до наступних зустрічей.",
  "chapters": {
    "textLanguage": "uk",
    "blocks": [
      {
        "title": "Вступ",
        "text": "Google підготував достойну відповідь Open. AI. Вам точно сподобається. Open AI збільшує ліміти на останні потужні моделі та втрачає мільйони доларів за те, що ми дякуємо ча GPT. Штучний інтелект навчився розмовляти з дельфінами. Дивимося, що сталося в світі штучного інтелекту та технологій за останній тиждень часу. А сталось багато чого цікавого. Того сідайте зручніше, ставте лайки і будемо починати.",
        "tokens": 101
      },
      {
        "title": "Найдешевша модель від Google",
        "text": "Google підготував достойну відповідь Openua і показав світу супердешеву і водночас супер потужну модель Gemini 2.5 Flash. Основна особливість цієї моделі - це те, що ця модель, вона є повністю гібридною. І ось цей от можливість різанного, можливість думання чи мислення можна включати і відключати. Мало того, якщо розробники працюють з цією моделлю, використовують її через API, то можна задавати певний бюджет надумання, що дозволить, знову ж таки, зменшити вартість і більше зробити процес планованим. Ну, і загалом, якщо подивитися на бенчмарки, то окрім того, що модель дійсно має привабливі ціни, вона так само по багатьом тестам, наприклад, як Human Last Exam та по іншим тестам дійсно достойно себе показує порівняно з іншими комерційними конкурентами. Якщо ж говорити про продуктивність моделі і її рівень на Rena Score, тобто наскільки модель дійсно потужно може працювати і ціна - це оця от горизонтальна лінія, то ми бачимо траєкторію, якою рухається Google. Тобто з випуском своїх моделей вони все рухаються правіше до здешевлення. Ну і знову ж таки їхні останні моделі, вони десь постійно залишаються зверху, що означає, що вони є лідерами з точки зору ефективності та продуктивності роботи. Зокрема, це їхні Gemon 2.5 Flash. Бачите, нічим не гірше від 4 О моделі, від GRК 3 моделі, тої самої 4.5 по продуктивності, але так само з точки зору десвизни вона десь в топі знаходиться моделей. Модель Google Flash 2.5 доступна через Google AI Studio. Тобто ми заходимо в інтерфейс, справа в нас є меню вибору. Ми дивимося ось модель, остання версія за 17 квітня. І власне ось тут ми бачимо ці налаштування. То ми можемо включити процес думання або вимкнути його. Ми можемо задати бюджет. Бюджет задається у вигляді токенів. Тобто, якщо я, наприклад, зараз викличу якийсь тестовий промт, проаналізувати це зображення, як доглядати за цією квіткою, то модель починає думати. Ми бачимо ось цей процес сінгу дуже схожий до процесу думання, які зараз є в О3 моделі, в О4 Mini моделі від Open AI. І коли завершується процес домання, ми можемо побачити, знову ж таки нашу фінальну відповідь, а так само скільки токенів модель використала для цього процесу. При умові, що якщо б я тут вказав обмеження, я би бачив, скільки використала в рамках цього мого обмеження. Так само модель Gemini Flash5 доступна з інтерфейсу класичного Gemini. Ось тут в меню ми можемо обрати цей 2,5 Flash Experimental. І ось я дам такий от запит, який прошу проаналізувати останні тарифи Трампа і підкріпити аналіз інформації з інтернету. Тобто модель є мультимодальною, вона вміє працювати з зображенням, зі звуком, вона вміє ходити в інтернет. І ось ми маємо ось таку от відповідь, яка підприклана інформацією з інтернету, а так само базується на основі оцього процесу думання. Так само модель є гібридною з точки зору підключення інструментів. Тобто, якщо потрібно, ця модель вміє в певний момент часу підключати різні інструменти. Чи це робота з файловою системою, чи це з пошуком, чи це з конвой, чи це з іншими інструментами, які доступні в пакеті від Gemini. Як я вже казав, Google дійсно за останній рік часу дуже сильно набирає оберти. І щоб ви зрозуміли наскільки це серйозно, давайте подивимося на цифри. Тобто на 2025 рік компанія Alphabet запланувала 75 млрд доларів на розробку технологій, пов'язані зі штучним інтелектом. Тобто це і хардверні речі, це є софтверні, це є розробки, це їхні Gem та інші речі. В порівнянні з тим самим Open AI, які, ну, насправді власних грошей не мають, вони здебільше ходять і шукають інвесторів. І десь вони кажуть, що ми плануємо підняти е суму в 40 млрд доларів цього року. 25-го року. І лише з них 10 млрд вже компанія СофTбанк та інші компанії оплатили Openю на його розробки. Тобто 10 млрд порівняно з 75 млрдми, які планує Google. Ну, ви самі розумієте діапазон цін. Знову ж таки, Google використовує власні кошти і власні RnD розробки працюють на його благо. Open знову ж таки шукає кошти. Тому я думаю марафон по розробці штучного інтелекту по нових технологіях цього року буде дійсно дуже і дуже цікавим.",
        "tokens": 736
      },
      {
        "title": "Gemma 3 - Локальна LLM",
        "text": "Ще одна потужна річ, яку зробив Google - це те, що тепер їхню GMA 3 модель можна запустити на локальному, звичайному домашньому комп'ютері або навіть на мобільному телефоні. Вони анонсували новий механізм квантування своєї ж моделі GM3. Якщо подивитися, то з того, що вони описують, використовуючи оце от quantization aware training механізм, вони дуже сильно зменшили використання ресурсів, зокрема пам'яті, яка необхідна для того, щоб запускати GMA3 моделі. Якщо раніше вона запускалася на Nvidia H100, то тепер її можна запустити на домашньому комп'ютері звичайною Nvidia RTX 3090. Ну і ось тут, якщо подивитися порівнянній, скільки взагалі потрібно графічних ресурсів для того, щоб запускати гема порівняно з тим самим Deeps чи Лама. Оці от крапочки це є кількість графічних процесорів, на яких запускається і працює модель. Ну і якщо трошки далі заглипитись в технічні деталі, то оцей от процес квантування, він насправді всім нам досить добре відомий. Єдине, що класична процес ковантування, він відбувається вже після того, як модель була запритрейнена. І відповідно зазвичай якість цього комантування, вона впливає на якість продуктивності моделі. Вона трошки погіршується. Що ж зробив Google? Вони інтегрували оцей от процес квантування в сам процес притренінгу. Тобто вони не чекають, поки модель там притрейнилась і вже її випускають в люди. Вони, коли вона притрейниться, пробують кожен крок якимсь чином стискати таким чином, оптимізуючи конфігурацію моделі. Це досить класне таке ноу-хау, яке вони розробили, яке вони придумали. І ось тут насправді на зображенні видно, яким чином оцей от процес квантування впливає на використання пам'яті, на використання ресурсів. Оце їхня 27 млрд параметрів модель. Це от класична модель, а це от квантована. Бачите, в три рази менше необхідно ресурсів для того, щоб працювати з цією моделлю. Де ж можна скачати цю модель, щоб запустити локально на комп'ютері? Прошу дуже. Олаama сервіс всім нам відомий. Можна в ньому прям вибрати конфігурацію моделі, чи звичайну модель класичну, чи ці нові стиснуті квантовані моделі. Скопіювати посилання і прошу дуже можна інсталювати GEMA 3 на власний комп'ютер чи на якийсь мобільний пристрій. У мене на каналі є окреме відео, де я розповідав, як встановити оламу, як через неї можна запускати локальні моделі. Тому, якщо ще не бачили, можете зайти подивитися.",
        "tokens": 408
      },
      {
        "title": "Прогноз від CEO Google Deep Mind",
        "text": "Ну і знову Google відзначився. Тільки цього разу їхній CEO компанії Deep Mind Demis HASABIS потрапив на сторінку Times через ряд дуже таких інтригованих і футуристичних прогнозів, які він бачить з точки зору розвитку штучного інтелекту. Ну і ось тут є знову ж таки перелік таких основних речей, які він розповідав в своєму 60тихвилинному інтерв'ю. До речі, можете інтерв'ю подивитися, воно доступно в публічному доступі в інтернеті. Зокрема, Хасабіс говорив, що десь в роки 20, 30, 20-35 все-таки ми досягнемо рівня загального штучного інтелекту. Тобто, ну, здавалось би, там наступних 5-10 років ми зможемо перетнути ось цю межу. Знову ж таки, ще одна така річ, про яку він розповідав і яка буде проривом ближчим часом, це те, що за 5-10 років штучний інтелект почне не просто повторювати ті речі, на основі яких він навчався, а почне дійсно генерувати щось унікальне, щось інноваційне, генерувати якісь гіпотези, генерувати якісь витвори. Тому це теж таку річ він прогнозує. Ну і загалом сфера розвитку медицини, розвитку ліків, вона теж дуже сильно просунеться з появою нового штучного інтелекту. Ну і ось тут, власне, він говорить про те, що протеїн контролює більшість елементів нашого організму, нашого тіла і взагалі оці всі дослідження навколо цього протеїну, структури його до появи ДІПМНДУ. ми там виконали лише 1 млн таких різних навчальних і дослідницьких процедур, то лише з появою дпмайну ми за останній рік часу дозволив нам Яй реалізувати порядка 200 млн різного роду досліджень і проектів. Це дуже великий скачок з точки зору власне медицини і того, як вона рухається далі. Ще одна річ, яку він говорить, це знову ж таки про те лікування, про діагностика, ранню діагностику. І вже дев'ять з 10 компаній на сьогоднішній день використовують штучний інтелект в своїй роботі. Про це ми теж, до речі, сьогодні поговоримо, бо Microsoft теж зробив одну дуже потужну розробку в сфері медицини. Ну і загалом оці всі дослідження, якщо раніше вони займали роки часу, то зараз з використанням штучного інтелекту це є години, можливо дні на дослідження, на якийсь аналіз, на якесь діагностування потрібно витратити.",
        "tokens": 391
      },
      {
        "title": "Copilot для лікарів",
        "text": "Ну і остання, але не менш важлива річ, знову ж таки,",
        "tokens": 11
      },
      {
        "title": "OpenAI збільшує ліміти",
        "text": "Open AI збільшує ліміти на останні потужні моделі та втрачає мільйони доларів за те, що ми дякуємо ча GPT.",
        "tokens": 20
      },
      {
        "title": "ChatGPT показує рекламу",
        "text": "",
        "tokens": 0
      },
      {
        "title": "OpenAI купує Windsurf",
        "text": "",
        "tokens": 0
      },
      {
        "title": "AI агент - дома на комп’ютері",
        "text": "",
        "tokens": 0
      },
      {
        "title": "AI розмовляє з дельфінами",
        "text": "Штучний інтелект навчився розмовляти з дельфінами.",
        "tokens": 7
      },
      {
        "title": "Dia - генератор емоційного звуку",
        "text": "",
        "tokens": 0
      },
      {
        "title": "Midjourney редактор зображень",
        "text": "",
        "tokens": 0
      },
      {
        "title": "Luma оновилась",
        "text": "",
        "tokens": 0
      },
      {
        "title": "Підписка та вподобайка",
        "text": "",
        "tokens": 0
      }
    ]
  },
  "semantic": {
    "textLanguage": "uk",
    "blocks": [
      {
        "title": "Вступ до новин штучного інтелекту",
        "text": "Google підготував достойну відповідь Open. AI. Вам точно сподобається. Open AI збільшує ліміти на останні потужні моделі та втрачає мільйони доларів за те, що ми дякуємо ча GPT. Штучний інтелект навчився розмовляти з дельфінами. Дивимося, що сталося в світі штучного інтелекту та технологій за останній тиждень часу. А сталось багато чого цікавого. Того сідайте зручніше, ставте лайки і будемо починати.",
        "tokens": 95
      },
      {
        "title": "Модель Gemini 2.5 Flash від Google",
        "text": "Google підготував достойну відповідь Openua і показав світу супердешеву і водночас супер потужну модель Gemini 2.5 Flash. Основна особливість цієї моделі - це те, що ця модель, вона є повністю гібридною. І ось цей от можливість різанного, можливість думання чи мислення можна включати і відключати. Мало того, якщо розробники працюють з цією моделлю, використовують її через API, то можна задавати певний бюджет надумання, що дозволить, знову ж таки, зменшити вартість і більше зробити процес планованим. Ну, і загалом, якщо подивитися на бенчмарки, то окрім того, що модель дійсно має привабливі ціни, вона так само по багатьом тестам, наприклад, як Human Last Exam та по іншим тестам дійсно достойно себе показує порівняно з іншими комерційними конкурентами.",
        "tokens": 144
      },
      {
        "title": "Продуктивність та доступність моделі Gemini 2.5 Flash",
        "text": "Якщо ж говорити про продуктивність моделі і її рівень на Rena Score, тобто наскільки модель дійсно потужно може працювати і ціна - це оця от горизонтальна лінія, то ми бачимо траєкторію, якою рухається Google. Тобто з випуском своїх моделей вони все рухаються правіше до здешевлення. Ну і знову ж таки їхні останні моделі, вони десь постійно залишаються зверху, що означає, що вони є лідерами з точки зору ефективності та продуктивності роботи. Зокрема, це їхні Gemon 2.5 Flash. Бачите, нічим не гірше від 4 О моделі, від GRК 3 моделі, тої самої 4.5 по продуктивності, але так само з точки зору десвизни вона десь в топі знаходиться моделей.",
        "tokens": 132
      },
      {
        "title": "Інтерфейс Google AI Studio для Gemini Flash 2.5",
        "text": "Модель Google Flash 2.5 доступна через Google AI Studio. Тобто ми заходимо в інтерфейс, справа в нас є меню вибору. Ми дивимося ось модель, остання версія за 17 квітня. І власне ось тут ми бачимо ці налаштування. То ми можемо включити процес думання або вимкнути його. Ми можемо задати бюджет. Бюджет задається у вигляді токенів. Тобто, якщо я, наприклад, зараз викличу якийсь тестовий промт, проаналізувати це зображення, як доглядати за цією квіткою, то модель починає думати. Ми бачимо ось цей процес сінгу дуже схожий до процесу думання, які зараз є в О3 моделі, в О4 Mini моделі від Open AI. І коли завершується процес домання, ми можемо побачити, знову ж таки нашу фінальну відповідь, а так само скільки токенів модель використала для цього процесу. При умові, що якщо б я тут вказав обмеження, я би бачив, скільки використала в рамках цього мого обмеження.",
        "tokens": 183
      },
      {
        "title": "Мультимодальні можливості Gemini Flash 2.5",
        "text": "Так само модель Gemini Flash5 доступна з інтерфейсу класичного Gemini. Ось тут в меню ми можемо обрати цей 2,5 Flash Experimental. І ось я дам такий от запит, який прошу проаналізувати останні тарифи Трампа і підкріпити аналіз інформації з інтернету. Тобто модель є мультимодальною, вона вміє працювати з зображенням, зі звуком, вона вміє ходити в інтернет. І ось ми маємо ось таку от відповідь, яка підприклана інформацією з інтернету, а так само базується на основі оцього процесу думання. Так само модель є гібридною з точки зору підключення інструментів. Тобто, якщо потрібно, ця модель вміє в певний момент часу підключати різні інструменти. Чи це робота з файловою системою, чи це з пошуком, чи це з конвой, чи це з іншими інструментами, які доступні в пакеті від Gemini.",
        "tokens": 150
      },
      {
        "title": "Інвестиції Google та OpenAI у ШІ",
        "text": "Як я вже казав, Google дійсно за останній рік часу дуже сильно набирає оберти. І щоб ви зрозуміли наскільки це серйозно, давайте подивимося на цифри. Тобто на 2025 рік компанія Alphabet запланувала 75 млрд доларів на розробку технологій, пов'язані зі штучним інтелектом. Тобто це і хардверні речі, це є софтверні, це є розробки, це їхні Gem та інші речі. В порівнянні з тим самим Open AI, які, ну, насправді власних грошей не мають, вони здебільше ходять і шукають інвесторів. І десь вони кажуть, що ми плануємо підняти е суму в 40 млрд доларів цього року. 25-го року. І лише з них 10 млрд вже компанія СофTбанк та інші компанії оплатили Openю на його розробки. Тобто 10 млрд порівняно з 75 млрдми, які планує Google. Ну, ви самі розумієте діапазон цін. Знову ж таки, Google використовує власні кошти і власні RnD розробки працюють на його благо. Open знову ж таки шукає кошти. Тому я думаю марафон по розробці штучного інтелекту по нових технологіях цього року буде дійсно дуже і дуже цікавим.",
        "tokens": 198
      },
      {
        "title": "Запуск моделі GMA 3 локально",
        "text": "Ще одна потужна річ, яку зробив Google - це те, що тепер їхню GMA 3 модель можна запустити на локальному, звичайному домашньому комп'ютері або навіть на мобільному телефоні. Вони анонсували новий механізм квантування своєї ж моделі GM3. Якщо подивитися, то з того, що вони описують, використовуючи оце от quantization aware training механізм, вони дуже сильно зменшили використання ресурсів, зокрема пам'яті, яка необхідна для того, щоб запускати GMA3 моделі. Якщо раніше вона запускалася на Nvidia H100, то тепер її можна запустити на домашньому комп'ютері звичайною Nvidia RTX 3090. Ну і ось тут, якщо подивитися порівнянній, скільки взагалі потрібно графічних ресурсів для того, щоб запускати гема порівняно з тим самим Deeps чи Лама. Оці от крапочки це є кількість графічних процесорів, на яких запускається і працює модель.",
        "tokens": 156
      },
      {
        "title": "Процес квантування моделей Google",
        "text": "Ну і якщо трошки далі заглипитись в технічні деталі, то оцей от процес квантування, він насправді всім нам досить добре відомий. Єдине, що класична процес ковантування, він відбувається вже після того, як модель була запритрейнена. І відповідно зазвичай якість цього комантування, вона впливає на якість продуктивності моделі. Вона трошки погіршується. Що ж зробив Google? Вони інтегрували оцей от процес квантування в сам процес притренінгу. Тобто вони не чекають, поки модель там притрейнилась і вже її випускають в люди. Вони, коли вона притрейниться, пробують кожен крок якимось чином стискати таким чином, оптимізуючи конфігурацію моделі. Це досить класне таке ноу-хау, яке вони розробили, яке вони придумали. І ось тут насправді на зображенні видно, яким чином оцей от процес квантування впливає на використання пам'яті, на використання ресурсів. Оце їхня 27 млрд параметрів модель. Це от класична модель, а це от квантована. Бачите, в три рази менше необхідно ресурсів для того, щоб працювати з цією моделлю.",
        "tokens": 182
      },
      {
        "title": "Де скачати модель GMA 3 для локального запуску",
        "text": "Де ж можна скачати цю модель, щоб запустити локально на комп'ютері? Прошу дуже. Олаama сервіс всім нам відомий. Можна в ньому прям вибрати конфігурацію моделі, чи звичайну модель класичну, чи ці нові стиснуті квантовані моделі. Скопіювати посилання і прошу дуже можна інсталювати GEMA 3 на власний комп'ютер чи на якийсь мобільний пристрій. У мене на каналі є окреме відео, де я розповідав, як встановити оламу, як через неї можна запускати локальні моделі. Тому, якщо ще не бачили, можете зайти подивитися.",
        "tokens": 111
      },
      {
        "title": "Інтерв'ю CEO DeepMind Деміса Хасабіса",
        "text": "Ну і знову Google відзначився. Тільки цього разу їхній CEO компанії Deep Mind Demis HASABIS потрапив на сторінку Times через ряд дуже таких інтригованих і футуристичних прогнозів, які він бачить з точки зору розвитку штучного інтелекту. Ну і ось тут є знову ж таки перелік таких основних речей, які він розповідав в своєму 60тихвилинному інтерв'ю. До речі, можете інтерв'ю подивитися, воно доступно в публічному доступі в інтернеті. Зокрема, Хасабіс говорив, що десь в роки 20, 30, 20-35 все-таки ми досягнемо рівня загального штучного інтелекту. Тобто, ну, здавалось би, там наступних 5-10 років ми зможемо перетнути ось цю межу.",
        "tokens": 144
      },
      {
        "title": "Прогнози розвитку ШІ від Деміса Хасабіса",
        "text": "Знову ж таки, ще одна така річ, про яку він розповідав і яка буде проривом ближчим часом, це те, що за 5-10 років штучний інтелект почне не просто повторювати ті речі, на основі яких він навчався, а почне дійсно генерувати щось унікальне, щось інноваційне, генерувати якісь гіпотези, генерувати якісь витвори. Тому це теж таку річ він прогнозує. Ну і загалом сфера розвитку медицини, розвитку ліків, вона теж дуже сильно просунеться з появою нового штучного інтелекту.",
        "tokens": 109
      },
      {
        "title": "Вплив ШІ на медицину та дослідження",
        "text": "Ну і ось тут, власне, він говорить про те, що протеїн контролює більшість елементів нашого організму, нашого тіла і взагалі оці всі дослідження навколо цього протеїну, структури його до появи ДІПМНДУ. ми там виконали лише 1 млн таких різних навчальних і дослідницьких процедур, то лише з появою дпмайну ми за останній рік часу дозволив нам Яй реалізувати порядка 200 млн різного роду досліджень і проектів. Це дуже великий скачок з точки зору власне медицини і того, як вона рухається далі. Ще одна річ, яку він говорить, це знову ж таки про те лікування, про діагностика, ранню діагностику. І вже дев'ять з 10 компаній на сьогоднішній день використовують штучний інтелект в своїй роботі. Про це ми теж, до речі, сьогодні поговоримо, бо Microsoft теж зробив одну дуже потужну розробку в сфері медицини. Ну і загалом оці всі дослідження, якщо раніше вони займали роки часу, то зараз з використанням штучного інтелекту це є години, можливо дні на дослідження, на якийсь аналіз, на якесь діагностування потрібно витратити.",
        "tokens": 175
      }
    ]
  }
}